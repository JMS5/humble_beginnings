{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2fde0d",
   "metadata": {},
   "source": [
    "# Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7aa5d14a-1aff-4f54-8a75-3eadf532a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, HTML\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/home/legorge/jre1.8.0_441\"\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "from pyspark.sql import SparkSession, functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01755fe",
   "metadata": {},
   "source": [
    "# Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec9b8ea-31f7-40a4-a249-3f18add4adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"demo\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247c2c97-a360-4c01-801e-b5c622998a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b429e16-295b-4fea-82a5-9f253645c946",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354024a5-4eaa-4627-abbd-d8387a244281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('data/data.parquet')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb6f84",
   "metadata": {},
   "source": [
    "# Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3a7e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'trip_distance', \n",
    "        'fare_amount', 'total_amount', 'tip_amount', 'tolls_amount', 'congestion_surcharge']\n",
    "clean_df = df.select(*cols).withColumn('real_amount', F.round(F.col('total_amount') - F.col('tolls_amount') - F.col('tip_amount'), 2))\n",
    "clean_df = clean_df.drop('total_amount', 'tip_amount', 'tolls_amount', 'fare_amount')\n",
    "clean_df.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301eb36",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1421d0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [schema.dataType for schema in clean_df.schema if ]\n",
    "# dir(clean_df.schema)\n",
    "\n",
    "\n",
    "clean_df = clean_df.withColumn(\"pickup_day_of_week\", F.dayofweek(\"tpep_pickup_datetime\")) \\\n",
    "       .withColumn(\"pickup_hour\", F.hour(\"tpep_pickup_datetime\"))\n",
    "clean_df = clean_df.withColumn(\"dropoff_day_of_week\", F.dayofweek(\"tpep_dropoff_datetime\")) \\\n",
    "       .withColumn(\"dropoff_hour\", F.hour(\"tpep_dropoff_datetime\"))\n",
    "\n",
    "clean_df = clean_df.withColumn(\"duration\", F.expr(\"timestampdiff(SECOND, tpep_pickup_datetime, tpep_dropoff_datetime) / 3600\")) \n",
    "\n",
    "clean_df = clean_df.drop('tpep_pickup_datetime', 'tpep_dropoff_datetime').cache()\n",
    "\n",
    "clean_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c88f08",
   "metadata": {},
   "source": [
    "# Split train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3803f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, train_weight, test_weight, seed=None):\n",
    "    # Split the DataFrame into training and test sets\n",
    "    train_df, test_df = df.randomSplit([train_weight, test_weight], seed)\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = split_dataframe(clean_df, 0.7, 0.3)\n",
    "# (2 075 719, 888 905)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.count(), train_df.count(), test_df.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8240b",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f20b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_random_forest_regression(df, features, label):\n",
    "    # Assemble features into a single vector column\n",
    "    assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "    \n",
    "    # Define the Random Forest Regression model\n",
    "    rf = RandomForestRegressor(featuresCol=\"features\", labelCol=label)\n",
    "    \n",
    "    # Set up the Pipeline\n",
    "    pipeline = Pipeline(stages=[assembler, rf])\n",
    "    \n",
    "    # Fit the model\n",
    "    model = pipeline.fit(df)\n",
    "    \n",
    "    # Print feature importances\n",
    "    print(\"Feature Importances: \" + str(model.stages[-1].featureImportances))\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = model.transform(df)\n",
    "    predictions.select(\"features\", label, \"prediction\").show()\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
